% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/algorithms.R
\name{CMIM}
\alias{CMIM}
\title{Minimal conditional mutual information maximisation filter}
\usage{
CMIM(X, Y, k = 3)
}
\arguments{
\item{X}{Attribute table, given as a data frame with only factor columns. \code{NA}s are not allowed.}

\item{Y}{Decision attribute; must be a factor. \code{NA}s are not allowed.}

\item{k}{Number of attributes to select. Must not exceed \code{ncol(X)}.}
}
\value{
A list with two elements: \code{selection}, a vector of names of the selected features in the selection order (note that it may be shorter than \code{k}), and \code{scores}, a vector of feature scores.
}
\description{
The method starts with an attribute of a maximal mutual information with the decision \eqn{Y}.
Then, it greedily adds attribute \eqn{X} with a maximal value of the following criterion:
\deqn{J(X)=\min_{W\in S} I(X;Y|W),}
where \eqn{S} is the set of already selected attributes.
The method stops either when no initial attribute with positive mutual information with \eqn{Y} can be found, or after \code{k} attributes are found.
}
\note{
CMIM is identical to the Informative Fragments (IF) method.
}
\references{
"Fast Binary Feature Selection using Conditional Mutual Information Maximisation" F. Fleuret, JMLR (2004)

"Object recognition with informative features and linear classification" M. Vidal-Naquet and S. Ullman, IEEE Conference on Computer Vision and Pattern Recognition (2003).
}
